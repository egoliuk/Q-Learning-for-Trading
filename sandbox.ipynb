{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.25.1)\n",
      "Collecting keras (from -r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 910kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/72/6b3264aa2889b7dde7663464b99587d95cd6a5f3b9b30181f14d78a63e64/tensorflow-2.0.0-cp37-cp37m-macosx_10_11_x86_64.whl (102.7MB)\n",
      "\u001b[K     |████████████████████████████████| 102.7MB 120kB/s eta 0:00:01   |██▍                             | 7.7MB 2.8MB/s eta 0:00:35     |██████████▏                     | 32.7MB 4.5MB/s eta 0:00:16     |██████████████▌                 | 46.5MB 5.2MB/s eta 0:00:11     |██████████████████▏             | 58.3MB 3.9MB/s eta 0:00:12\n",
      "\u001b[?25hCollecting sklearn (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting h5py (from -r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/8b/4d01ae9a9d50a0bcc7b0b9aae41785d8d9de6fa9bba04dc20b1582181d2d/h5py-2.10.0-cp37-cp37m-macosx_10_6_intel.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gym==0.9.4 (from -r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/9f/b50f4c04a97e316ebfccae3104e5edbfe7bc1c687ee9ebeca6fa6343d197/gym-0.9.4.tar.gz (157kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages (from keras->-r requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from keras->-r requirements.txt (line 3)) (1.3.1)\n",
      "Collecting keras-applications>=1.0.6 (from keras->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pyyaml (from keras->-r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorflow->-r requirements.txt (line 4)) (0.33.4)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting grpcio>=1.8.6 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/07/f1d41d10519ca165b0e078949078f20beb57e7e46dc0f1d56b73bb01270a/grpcio-1.24.1-cp37-cp37m-macosx_10_9_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 8.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 11.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 13.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c6/a8b6a74ab1e165f0aaa673a46f5c895af8780976880c98934ae82060356d/protobuf-3.10.0-cp37-cp37m-macosx_10_9_intel.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 5)) (0.21.3)\n",
      "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.7/site-packages (from gym==0.9.4->-r requirements.txt (line 7)) (2.22.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.7/site-packages (from gym==0.9.4->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->-r requirements.txt (line 4)) (41.0.1)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<2.1.0,>=2.0.0->tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 7.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow->-r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 9.2MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.0->gym==0.9.4->-r requirements.txt (line 7)) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests>=2.0->gym==0.9.4->-r requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.0->gym==0.9.4->-r requirements.txt (line 7)) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.0->gym==0.9.4->-r requirements.txt (line 7)) (1.25.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from pyglet>=1.2.0->gym==0.9.4->-r requirements.txt (line 7)) (0.18.0)\n",
      "Building wheels for collected packages: sklearn, gym, pyyaml, termcolor, absl-py, opt-einsum, wrapt, gast\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/2f/ae/a0/126678adc5f1f8905309a4712ea29537999787f610edbcb0a4\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/dasha_awesome/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built sklearn gym pyyaml termcolor absl-py opt-einsum wrapt gast\n",
      "Installing collected packages: keras-preprocessing, h5py, keras-applications, pyyaml, keras, termcolor, absl-py, astor, opt-einsum, protobuf, grpcio, werkzeug, markdown, tensorboard, wrapt, google-pasta, gast, tensorflow-estimator, tensorflow, sklearn, gym\n",
      "  Found existing installation: gym 0.15.3\n",
      "    Uninstalling gym-0.15.3:\n",
      "      Successfully uninstalled gym-0.15.3\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.24.1 gym-0.9.4 h5py-2.10.0 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.10.0 pyyaml-5.1.2 sklearn-0.0 tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.0 termcolor-1.1.0 werkzeug-0.16.0 wrapt-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time as tm\n",
    "import numpy as np\n",
    "# import argparse\n",
    "import re\n",
    "\n",
    "from envs import TradingEnv\n",
    "from agent import DQNAgent\n",
    "from utils import get_data, get_scaler, maybe_make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    mode = 'train'\n",
    "    initial_invest = 20000\n",
    "    episode = 200\n",
    "    batch_size = 32\n",
    "    weights = '{}-dqn.h5'\n",
    "\n",
    "maybe_make_dir('weights')\n",
    "maybe_make_dir('portfolio_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 32)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 27)                891       \n",
      "=================================================================\n",
      "Total params: 2,203\n",
      "Trainable params: 2,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "timestamp = tm.strftime('%Y%m%d%H%M')\n",
    "\n",
    "data = np.around(get_data())\n",
    "train_data = data[:, :3526]\n",
    "test_data = data[:, 3526:]\n",
    "\n",
    "env = TradingEnv(train_data, args.initial_invest)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "scaler = get_scaler(env)\n",
    "\n",
    "portfolio_value = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'test':\n",
    "    # remake the env with test data\n",
    "    env = TradingEnv(test_data, args.initial_invest)\n",
    "    # load trained weights\n",
    "    agent.load(args.weights)\n",
    "    # when test, the timestamp is same as time when weights was trained\n",
    "    timestamp = re.findall(r'\\d{12}', args.weights)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/200, episode end value: 37533.0\n",
      "episode: 2/200, episode end value: 19057.0\n",
      "episode: 3/200, episode end value: 19278.0\n",
      "episode: 4/200, episode end value: 12777.0\n",
      "episode: 5/200, episode end value: 3476.0\n",
      "episode: 6/200, episode end value: 52455.0\n",
      "episode: 7/200, episode end value: 8832.0\n",
      "episode: 8/200, episode end value: 9177.0\n",
      "episode: 9/200, episode end value: 4554.0\n",
      "episode: 10/200, episode end value: 14485.0\n",
      "episode: 11/200, episode end value: 16791.0\n",
      "episode: 12/200, episode end value: 13694.0\n",
      "episode: 13/200, episode end value: 6864.0\n",
      "episode: 14/200, episode end value: 6372.0\n",
      "episode: 15/200, episode end value: 24884.0\n",
      "episode: 16/200, episode end value: 10187.0\n",
      "episode: 17/200, episode end value: 8553.0\n",
      "episode: 18/200, episode end value: 13670.0\n",
      "episode: 19/200, episode end value: 22494.0\n",
      "episode: 20/200, episode end value: 15614.0\n",
      "episode: 21/200, episode end value: 32037.0\n",
      "episode: 22/200, episode end value: 45438.0\n",
      "episode: 23/200, episode end value: 3102.0\n",
      "episode: 24/200, episode end value: 28089.0\n",
      "episode: 25/200, episode end value: 12497.0\n",
      "episode: 26/200, episode end value: 15210.0\n",
      "episode: 27/200, episode end value: 13684.0\n",
      "episode: 28/200, episode end value: 39779.0\n",
      "episode: 29/200, episode end value: 69696.0\n",
      "episode: 30/200, episode end value: 35983.0\n",
      "episode: 31/200, episode end value: 4813.0\n",
      "episode: 32/200, episode end value: 12568.0\n",
      "episode: 33/200, episode end value: 5477.0\n",
      "episode: 34/200, episode end value: 39400.0\n",
      "episode: 35/200, episode end value: 8878.0\n",
      "episode: 36/200, episode end value: 36674.0\n",
      "episode: 37/200, episode end value: 11942.0\n",
      "episode: 38/200, episode end value: 51542.0\n",
      "episode: 39/200, episode end value: 9708.0\n",
      "episode: 40/200, episode end value: 20934.0\n",
      "episode: 41/200, episode end value: 75513.0\n",
      "episode: 42/200, episode end value: 31281.0\n",
      "episode: 43/200, episode end value: 88401.0\n",
      "episode: 44/200, episode end value: 15878.0\n",
      "episode: 45/200, episode end value: 42617.0\n",
      "episode: 46/200, episode end value: 46466.0\n",
      "episode: 47/200, episode end value: 13245.0\n",
      "episode: 48/200, episode end value: 77267.0\n",
      "episode: 49/200, episode end value: 9066.0\n",
      "episode: 50/200, episode end value: 5722.0\n",
      "episode: 51/200, episode end value: 33878.0\n",
      "episode: 52/200, episode end value: 26149.0\n",
      "episode: 53/200, episode end value: 4996.0\n",
      "episode: 54/200, episode end value: 62703.0\n",
      "episode: 55/200, episode end value: 21948.0\n",
      "episode: 56/200, episode end value: 23602.0\n",
      "episode: 57/200, episode end value: 33885.0\n",
      "episode: 58/200, episode end value: 43791.0\n",
      "episode: 59/200, episode end value: 12326.0\n",
      "episode: 60/200, episode end value: 28688.0\n",
      "episode: 61/200, episode end value: 45693.0\n",
      "episode: 62/200, episode end value: 11939.0\n",
      "episode: 63/200, episode end value: 16559.0\n",
      "episode: 64/200, episode end value: 34033.0\n",
      "episode: 65/200, episode end value: 11380.0\n",
      "episode: 66/200, episode end value: 91629.0\n",
      "episode: 67/200, episode end value: 10932.0\n",
      "episode: 68/200, episode end value: 13432.0\n",
      "episode: 69/200, episode end value: 23224.0\n",
      "episode: 70/200, episode end value: 6134.0\n",
      "episode: 71/200, episode end value: 59677.0\n",
      "episode: 72/200, episode end value: 18926.0\n",
      "episode: 73/200, episode end value: 10251.0\n",
      "episode: 74/200, episode end value: 5973.0\n",
      "episode: 75/200, episode end value: 16343.0\n",
      "episode: 76/200, episode end value: 14657.0\n",
      "episode: 77/200, episode end value: 11859.0\n",
      "episode: 78/200, episode end value: 5907.0\n",
      "episode: 79/200, episode end value: 8920.0\n",
      "episode: 80/200, episode end value: 10334.0\n",
      "episode: 81/200, episode end value: 8649.0\n",
      "episode: 82/200, episode end value: 24846.0\n",
      "episode: 83/200, episode end value: 39317.0\n",
      "episode: 84/200, episode end value: 14630.0\n",
      "episode: 85/200, episode end value: 19817.0\n",
      "episode: 86/200, episode end value: 57530.0\n",
      "episode: 87/200, episode end value: 60964.0\n",
      "episode: 88/200, episode end value: 10112.0\n",
      "episode: 89/200, episode end value: 17157.0\n",
      "episode: 90/200, episode end value: 12426.0\n",
      "episode: 91/200, episode end value: 58105.0\n",
      "episode: 92/200, episode end value: 64105.0\n",
      "episode: 93/200, episode end value: 44510.0\n",
      "episode: 94/200, episode end value: 57760.0\n",
      "episode: 95/200, episode end value: 78329.0\n",
      "episode: 96/200, episode end value: 83172.0\n",
      "episode: 97/200, episode end value: 113934.0\n",
      "episode: 98/200, episode end value: 45835.0\n",
      "episode: 99/200, episode end value: 59315.0\n",
      "episode: 100/200, episode end value: 60890.0\n",
      "episode: 101/200, episode end value: 67909.0\n",
      "episode: 102/200, episode end value: 87437.0\n",
      "episode: 103/200, episode end value: 81660.0\n",
      "episode: 104/200, episode end value: 10741.0\n",
      "episode: 105/200, episode end value: 14246.0\n",
      "episode: 106/200, episode end value: 59647.0\n",
      "episode: 107/200, episode end value: 47470.0\n",
      "episode: 108/200, episode end value: 59474.0\n",
      "episode: 109/200, episode end value: 35450.0\n",
      "episode: 110/200, episode end value: 10928.0\n",
      "episode: 111/200, episode end value: 17379.0\n",
      "episode: 112/200, episode end value: 13237.0\n",
      "episode: 113/200, episode end value: 30276.0\n",
      "episode: 114/200, episode end value: 9832.0\n",
      "episode: 115/200, episode end value: 69789.0\n",
      "episode: 116/200, episode end value: 21584.0\n",
      "episode: 117/200, episode end value: 23891.0\n",
      "episode: 118/200, episode end value: 25092.0\n",
      "episode: 119/200, episode end value: 157048.0\n",
      "episode: 120/200, episode end value: 44121.0\n",
      "episode: 121/200, episode end value: 15770.0\n",
      "episode: 122/200, episode end value: 91157.0\n",
      "episode: 123/200, episode end value: 89100.0\n",
      "episode: 124/200, episode end value: 50018.0\n",
      "episode: 125/200, episode end value: 106775.0\n",
      "episode: 126/200, episode end value: 43958.0\n",
      "episode: 127/200, episode end value: 36940.0\n",
      "episode: 128/200, episode end value: 31957.0\n",
      "episode: 129/200, episode end value: 51433.0\n",
      "episode: 130/200, episode end value: 6741.0\n",
      "episode: 131/200, episode end value: 21317.0\n",
      "episode: 132/200, episode end value: 9681.0\n",
      "episode: 133/200, episode end value: 26441.0\n",
      "episode: 134/200, episode end value: 6846.0\n",
      "episode: 135/200, episode end value: 18860.0\n",
      "episode: 136/200, episode end value: 36332.0\n",
      "episode: 137/200, episode end value: 13953.0\n",
      "episode: 138/200, episode end value: 41882.0\n",
      "episode: 139/200, episode end value: 18691.0\n",
      "episode: 140/200, episode end value: 19760.0\n",
      "episode: 141/200, episode end value: 45765.0\n",
      "episode: 142/200, episode end value: 86203.0\n",
      "episode: 143/200, episode end value: 69892.0\n",
      "episode: 144/200, episode end value: 64207.0\n",
      "episode: 145/200, episode end value: 69305.0\n",
      "episode: 146/200, episode end value: 22168.0\n",
      "episode: 147/200, episode end value: 62521.0\n",
      "episode: 148/200, episode end value: 52174.0\n",
      "episode: 149/200, episode end value: 78517.0\n",
      "episode: 150/200, episode end value: 57956.0\n",
      "episode: 151/200, episode end value: 103828.0\n",
      "episode: 152/200, episode end value: 18561.0\n",
      "episode: 153/200, episode end value: 65099.0\n",
      "episode: 154/200, episode end value: 78373.0\n",
      "episode: 155/200, episode end value: 64946.0\n",
      "episode: 156/200, episode end value: 75493.0\n",
      "episode: 157/200, episode end value: 69485.0\n",
      "episode: 158/200, episode end value: 118076.0\n",
      "episode: 159/200, episode end value: 32584.0\n",
      "episode: 160/200, episode end value: 79338.0\n",
      "episode: 161/200, episode end value: 103526.0\n",
      "episode: 162/200, episode end value: 35658.0\n",
      "episode: 163/200, episode end value: 58057.0\n",
      "episode: 164/200, episode end value: 105967.0\n",
      "episode: 165/200, episode end value: 91997.0\n",
      "episode: 166/200, episode end value: 113761.0\n",
      "episode: 167/200, episode end value: 62167.0\n",
      "episode: 168/200, episode end value: 163526.0\n",
      "episode: 169/200, episode end value: 96985.0\n",
      "episode: 170/200, episode end value: 105034.0\n",
      "episode: 171/200, episode end value: 129912.0\n",
      "episode: 172/200, episode end value: 99397.0\n",
      "episode: 173/200, episode end value: 96998.0\n",
      "episode: 174/200, episode end value: 128845.0\n",
      "episode: 175/200, episode end value: 43619.0\n",
      "episode: 176/200, episode end value: 39560.0\n",
      "episode: 177/200, episode end value: 39837.0\n",
      "episode: 178/200, episode end value: 90050.0\n",
      "episode: 179/200, episode end value: 78345.0\n",
      "episode: 180/200, episode end value: 18217.0\n",
      "episode: 181/200, episode end value: 8483.0\n",
      "episode: 182/200, episode end value: 12364.0\n",
      "episode: 183/200, episode end value: 5797.0\n",
      "episode: 184/200, episode end value: 28732.0\n",
      "episode: 185/200, episode end value: 40472.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 186/200, episode end value: 31070.0\n",
      "episode: 187/200, episode end value: 23773.0\n",
      "episode: 188/200, episode end value: 25605.0\n",
      "episode: 189/200, episode end value: 14935.0\n",
      "episode: 190/200, episode end value: 63729.0\n",
      "episode: 191/200, episode end value: 30720.0\n",
      "episode: 192/200, episode end value: 16664.0\n",
      "episode: 193/200, episode end value: 23043.0\n",
      "episode: 194/200, episode end value: 11388.0\n",
      "episode: 195/200, episode end value: 16071.0\n",
      "episode: 196/200, episode end value: 28051.0\n",
      "episode: 197/200, episode end value: 20252.0\n",
      "episode: 198/200, episode end value: 8427.0\n",
      "episode: 199/200, episode end value: 13324.0\n",
      "episode: 200/200, episode end value: 59291.0\n"
     ]
    }
   ],
   "source": [
    "for e in range(args.episode):\n",
    "    state = env.reset()\n",
    "    state = scaler.transform([state])\n",
    "    \n",
    "    for time in range(env.n_step):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = scaler.transform([next_state])\n",
    "        if args.mode == 'train':\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, episode end value: {}\".format(e + 1, args.episode, info['cur_val']))\n",
    "            portfolio_value.append(info['cur_val']) # append episode end portfolio value\n",
    "            break\n",
    "        if args.mode == 'train' and len(agent.memory) > args.batch_size:\n",
    "            agent.replay(args.batch_size)\n",
    "    if args.mode == 'train' and (e + 1) % 10 == 0:  # checkpoint weights\n",
    "        agent.save('weights/{}-dqn.h5'.format(timestamp))\n",
    "\n",
    "# save portfolio value history to disk\n",
    "with open('portfolio_val/{}-{}.p'.format(timestamp, args.mode), 'wb') as fp:\n",
    "    pickle.dump(portfolio_value, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
